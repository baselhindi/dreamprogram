---
layout: post
title: Week 1 (Jul 18 - Jul 22)
---


This week our primary focus was to finalize our submission for the ACM Symposium on User Interface Software and Technology (UIST). We paused system development and focused on generating demonstration clips that would constitute our video submission to UIST. This entailed multiple steps. Firstly, I sifted through our existing output videos from both the baseline outputs (modern tennis broadcasts) and the application outputs (historical broadcasts, recreational videos uploaded to youtube.com, and gameplay from tennis video games). 

I selected one or two segmentation clips from each of the above categories that would be long enough to highlight our system’s functionality. It was important that the player detection, ball detection, and court detection were all functioning properly for each of the clips I selected, and that the gameplay was engaging to a viewer. I then smoothed the tennis ball coordinates using the tool that we produced last week in order to remove misdetections and outliers in the ball tracking. The output of this process is a new file containing smoothed ball coordinates, which can then be handed off to a colleague in the lab to generate the spatialized audio associated with that gameplay. This new file is also the basis for the birds eye view representation of the game, which I overlayed on top of the original video as well. Lastly, I edited the clips to contain both the original audio and the spatialized audio so that Blind or Low Vision (BLV) users could benefit from both audio sources. Using this, we were able to submit the demo videos along with the paper to UIST. 

On Friday, we had a guest speaker from Microsoft Research and Snap Inc, Dr. Martez Mott. He spoke about improving accessibility to VR and touch screen calibration for users with mobility impairments like Parkinson’s disease or Cerebral Palsy. It was eye-opening to hear about the different modalities that can be implemented to offer improved VR accessibility to people with mobility impairments, like leveraging eye-movement or head movement as an alternative to double handed controllers. As someone with a hardware background and a growing passion for computer vision , it was inspiring to see these fields come together to improve accessibility. 
